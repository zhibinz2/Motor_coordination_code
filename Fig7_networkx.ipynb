{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file ./util/chan_locs/TMSi32chan_loc_small.fif...\n",
      "Isotrak not found\n",
      "    Range : 0 ... 2000 =      0.000 ...     1.000 secs\n",
      "Ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1000502/3388744621.py:24: RuntimeWarning: This filename (./util/chan_locs/TMSi32chan_loc_small.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  mne_object=mne.io.read_raw_fif('./util/chan_locs/TMSi32chan_loc_small.fif')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "from os import listdir\n",
    "\n",
    "from hdf5storage import loadmat, savemat \n",
    "import numpy as np \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from scipy import signal \n",
    "from scipy.signal import sosfiltfilt\n",
    "from scipy.signal import hilbert\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.stats import sem\n",
    "from scipy import stats\n",
    "from scipy.stats import f_oneway\n",
    "from numpy.polynomial.polynomial import polyfit, polyval\n",
    "from scipy.stats import pointbiserialr\n",
    "import networkx as nx\n",
    "from sklearn.cross_decomposition import PLSCanonical\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import mne\n",
    "mne_object=mne.io.read_raw_fif('./util/chan_locs/TMSi32chan_loc_small.fif')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Color Scheme) \n",
    "red         = [1, 0, 0]\n",
    "pink        = [1, 0.65, 0.75]\n",
    "black       = [0, 0, 0]\n",
    "white       = [1, 1, 1]\n",
    "blue        = [0, 0, 1]\n",
    "mediumblue  = [0, 0.4, 0.7]\n",
    "green       = [0, 1, 0]\n",
    "darkgreen   = [0, 0.5, 0]\n",
    "grey        = [0.5, 0.5, 0.5]\n",
    "yellow      = [1, 1, 0]\n",
    "deepyellow  = [1, 0.8, 0.2]\n",
    "gold        = [212/255, 175/255, 55/255]\n",
    "brown       = [150/255, 75/255, 0]\n",
    "magenta     = [1, 0, 1] \n",
    "cyan        = [0, 1, 1]  \n",
    "purple      = [0.6, 0.1, 0.9]\n",
    "\n",
    "# % https://www.mathworks.com/help/matlab/creating_plots/specify-plot-colors.html\n",
    "matlab_blue     = [0, 0.4470, 0.7410]\n",
    "matlab_orange   = [0.8500, 0.3250, 0.0980]\n",
    "matlab_gold     = [0.9290, 0.6940, 0.1250]\n",
    "matlab_purple   = [0.4940, 0.1840, 0.5560]\n",
    "matlab_green    = [0.4660, 0.6740, 0.1880]\n",
    "matlab_cyan     = [0.3010, 0.7450, 0.9330]\n",
    "matlab_red      = [0.6350, 0.0780, 0.1840]\n",
    "\n",
    "# combine colors\n",
    "condicolors = [darkgreen, red, blue, magenta, purple, purple]\n",
    "dire3colors = [darkgreen, brown, magenta]\n",
    "syn2colors = [darkgreen, pink]\n",
    "HNLcolors = [darkgreen, deepyellow, pink]\n",
    "freq7colors = [black, red, deepyellow, darkgreen, matlab_blue, blue, matlab_purple]\n",
    "\n",
    "color_4st=[matlab_green,red,blue,black]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load chan locs for topoplots\n",
    "dict_loc=loadmat('./util/chan_locs/xyzlabels.mat')\n",
    "x=dict_loc['x']\n",
    "y=dict_loc['y']\n",
    "z=dict_loc['z']\n",
    "labels=dict_loc['labels']\n",
    "\n",
    "# adjust coords for nilearn plots\n",
    "coords=np.zeros((32,3))\n",
    "for i in range(32):\n",
    "    coords[i,:]=[x[i]*700, y[i]*900-15, z[i]*950-15]\n",
    "\n",
    "#  construct text for networkx labels\n",
    "labeldict = {}\n",
    "for i in range(32):\n",
    "    labeldict[i]=labels[i]\n",
    "\n",
    "# load pos for networkx plots\n",
    "pos_mat=loadmat('./util/chan_locs/pos.mat')\n",
    "pos=pos_mat['pos']\n",
    "\n",
    "\n",
    "# construct full edges_list\n",
    "edges_list=list() # each edge is a two element tuple\n",
    "for i in range(32):\n",
    "    for j in range(32):\n",
    "        if i<j: # use indicies to remove half of edges and colors and the diagonal\n",
    "            edges_list.append((i,j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable names for plotting\n",
    "states4names=['Independent','Leading','Following','Mutual']\n",
    "syn2names=['Synchronization','Syncopation']\n",
    "states3names=['Independent','Unidirectional','Bidirectional']\n",
    "band_labels = ['Delta','Theta','Alpha','Mu','Beta1','Beta2','Gamma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['L_lead_ind', 'L_lead_synch_ind', 'L_lead_synco_ind', 'Mutual_ind', 'Mutual_synch_ind', 'Mutual_synco_ind', 'R_lead_ind', 'R_lead_synch_ind', 'R_lead_synco_ind', 'Uncoupled_ind', 'Uncoupled_synch_ind', 'Uncoupled_synco_ind', 'condi4_ind', 'syn2_condi4_ind', 'syn_ind', 'synch_condi4_ind', 'synch_ind', 'synco_condi4_ind', 'synco_ind'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices=loadmat('Indicies.mat')\n",
    "syn2_condi4_ind     = indices['syn2_condi4_ind']\n",
    "indices.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hurstdict = loadmat('H.mat')\n",
    "hurstdict.keys()\n",
    "H= hurstdict['H']\n",
    "H.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#organize hurst exponents \n",
    "H_follow_synco = np.zeros(36)\n",
    "H_lead_synco = np.zeros(36)\n",
    "H_ind_synco = np.zeros(36)\n",
    "H_mutual_synco = np.zeros(36)\n",
    "H_follow_synch = np.zeros(36)\n",
    "H_lead_synch = np.zeros(36)\n",
    "H_ind_synch = np.zeros(36)\n",
    "H_mutual_synch = np.zeros(36)\n",
    "\n",
    "H_follow_synco[0:18] = H[indices['R_lead_synco_ind'],0]\n",
    "H_follow_synco[18:36] = H[indices['L_lead_synco_ind'],1]\n",
    "H_lead_synco[0:18] = H[indices['L_lead_synco_ind'],0]\n",
    "H_lead_synco[18:36] =H[indices['R_lead_synco_ind'],1]\n",
    "H_mutual_synco[0:18] = H[indices['Mutual_synco_ind'],0] \n",
    "H_mutual_synco[18:36] = H[indices['Mutual_synco_ind'],1]\n",
    "H_ind_synco[0:18] = H[indices['Uncoupled_synco_ind'],0]\n",
    "H_ind_synco[18:36] = H[indices['Uncoupled_synco_ind'],1]\n",
    "\n",
    "H_follow_synch[0:18] = H[indices['R_lead_synch_ind'],0]\n",
    "H_follow_synch[18:36] = H[indices['L_lead_synch_ind'],1]\n",
    "H_lead_synch[0:18] = H[indices['L_lead_synch_ind'],0]\n",
    "H_lead_synch[18:36] =H[indices['R_lead_synch_ind'],1]\n",
    "H_mutual_synch[0:18] = H[indices['Mutual_synch_ind'],0] \n",
    "H_mutual_synch[18:36] = H[indices['Mutual_synch_ind'],1]\n",
    "H_ind_synch[0:18] = H[indices['Uncoupled_synch_ind'],0]\n",
    "H_ind_synch[18:36] = H[indices['Uncoupled_synch_ind'],1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organized into np\n",
    "H_synch=[H_ind_synch, H_lead_synch, H_follow_synch, H_mutual_synch]\n",
    "H_synco=[H_ind_synco, H_lead_synco, H_follow_synco, H_mutual_synco]\n",
    "H_syn=[H_synch, H_synco]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrdict=loadmat('Corr_eeg144.mat')\n",
    "\n",
    "eeg_empirical_correlation144x2  = corrdict['eeg_empirical_correlation144x2']     \n",
    "eeg_partial_correlation144x2    = corrdict['eeg_partial_correlation144x2']       \n",
    "intervals144                    = corrdict['intervals144']                       \n",
    "samples144                      = corrdict['samples144']                         \n",
    "session144                      = corrdict['session144']                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#organize the adjacency matrices from partial correlation\n",
    "eeg_partial_correlation144x2 = eeg_partial_correlation144x2.astype(bool)\n",
    "        \n",
    "A_follow_synco = np.zeros((36,7,32,32))\n",
    "A_lead_synco = np.zeros((36,7,32,32))\n",
    "A_ind_synco = np.zeros((36,7,32,32))\n",
    "A_mutual_synco = np.zeros((36,7,32,32))\n",
    "A_follow_synch = np.zeros((36,7,32,32))\n",
    "A_lead_synch = np.zeros((36,7,32,32))\n",
    "A_ind_synch = np.zeros((36,7,32,32))\n",
    "A_mutual_synch = np.zeros((36,7,32,32))\n",
    "\n",
    "A_follow_synco[0:18,:,:,:] = eeg_partial_correlation144x2[indices['R_lead_synco_ind'],0,:,:,:]\n",
    "A_follow_synco[18:36,:,:,:] = eeg_partial_correlation144x2[indices['L_lead_synco_ind'],1,:,:,:]\n",
    "A_lead_synco[0:18,:,:,:] = eeg_partial_correlation144x2[indices['L_lead_synco_ind'],0,:,:,:]\n",
    "A_lead_synco[18:36,:,:,:] =eeg_partial_correlation144x2[indices['R_lead_synco_ind'],1,:,:,:]\n",
    "A_mutual_synco[0:18,:,:,:] = eeg_partial_correlation144x2[indices['Mutual_synco_ind'],0,:,:,:] \n",
    "A_mutual_synco[18:36,:,:,:] = eeg_partial_correlation144x2[indices['Mutual_synco_ind'],1,:,:,:]\n",
    "A_ind_synco[0:18,:,:,:] = eeg_partial_correlation144x2[indices['Uncoupled_synco_ind'],0,:,:,:]\n",
    "A_ind_synco[18:36,:,:,:] = eeg_partial_correlation144x2[indices['Uncoupled_synco_ind'],1,:,:,:]\n",
    "\n",
    "A_follow_synch[0:18,:,:,:] = eeg_partial_correlation144x2[indices['R_lead_synch_ind'],0,:,:,:]\n",
    "A_follow_synch[18:36,:,:,:] = eeg_partial_correlation144x2[indices['L_lead_synch_ind'],1,:,:,:]\n",
    "A_lead_synch[0:18,:,:,:] = eeg_partial_correlation144x2[indices['L_lead_synch_ind'],0,:,:,:]\n",
    "A_lead_synch[18:36,:,:,:] =eeg_partial_correlation144x2[indices['R_lead_synch_ind'],1,:,:,:]\n",
    "A_mutual_synch[0:18,:,:,:] = eeg_partial_correlation144x2[indices['Mutual_synch_ind'],0,:,:,:] \n",
    "A_mutual_synch[18:36,:,:,:] = eeg_partial_correlation144x2[indices['Mutual_synch_ind'],1,:,:,:]\n",
    "A_ind_synch[0:18,:,:,:] = eeg_partial_correlation144x2[indices['Uncoupled_synch_ind'],0,:,:,:]\n",
    "A_ind_synch[18:36,:,:,:] = eeg_partial_correlation144x2[indices['Uncoupled_synch_ind'],1,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organized into np array (edges)\n",
    "A_synch=[A_ind_synch, A_lead_synch, A_follow_synch, A_mutual_synch]\n",
    "A_synco=[A_ind_synco, A_lead_synco, A_follow_synco, A_mutual_synco]\n",
    "A_syn=[A_synch, A_synco]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhibinz2/anaconda3/envs/mne/lib/python3.10/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "# real correlation (edges)\n",
    "r_AH=np.zeros((2,4,7,32,32))\n",
    "p_AH=np.zeros((2,4,7,32,32))\n",
    "for syn in range(2):\n",
    "    for st in range(4):\n",
    "        for freq in range(7):\n",
    "            for k in range(32):\n",
    "                for l in range(32):\n",
    "                    r_AH[syn,st,freq,k,l], p_AH[syn,st,freq,k,l] = pointbiserialr(\n",
    "                        A_syn[syn][st][:,freq,k,l],H_syn[syn][st])\n",
    "# 46 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This step takes over an hour, output was saved already, can skip to save time\n",
    "# # simulate 36 random graph to get correlation and repeat 100 times (edges)\n",
    "# r100_4ArH=np.zeros((100,2,4,7,32,32)) # Distribution\n",
    "# for r in range(100):\n",
    "#     # construct 36 random network with matched number of edges\n",
    "#     Ar_syn=np.zeros((2,4,36,7,32,32)) # 36 random graph\n",
    "#     for syn in range(2):\n",
    "#         for st in range(4): # only for mutual\n",
    "#             for tr in range(36):\n",
    "#                 for freq in range(7):\n",
    "#                     G=nx.from_numpy_array(A_syn[syn][st][tr,freq,:,:])\n",
    "#                     nEdges = len(G.edges())\n",
    "#                     R=nx.gnm_random_graph(32, nEdges, seed=None, directed=False)\n",
    "#                     Ar = nx.adjacency_matrix(R).toarray() # random graph matrix\n",
    "#                     Ar_syn[syn,st,tr,freq,:,:] = Ar\n",
    "#                     del(G,R,Ar)\n",
    "#     # compute correlation\n",
    "#     r_ArH=np.zeros((2,4,7,32,32))\n",
    "#     p_ArH=np.zeros((2,4,7,32,32))\n",
    "#     for syn in range(2):\n",
    "#         for st in range(4):\n",
    "#             for freq in range(7):\n",
    "#                 for k in range(32):\n",
    "#                     for l in range(32):\n",
    "#                         r_ArH[syn,st,freq,k,l], p_ArH[syn,st,freq,k,l]= pointbiserialr(\n",
    "#                             Ar_syn[syn][st][:,freq,k,l],H_syn[syn][st])\n",
    "#                 r100_4ArH[r,syn,st,freq,:,:]=r_ArH[syn,st,freq,:,:]\n",
    "\n",
    "# # this step takes about 18 min x 4 st = 72 min, to save time, the output was saved already\n",
    "# outdict = dict()\n",
    "# outdict['r100_4ArH']       = r100_4ArH\n",
    "# savemat('r100_4ArH',outdict,store_python_metadata = True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdict=loadmat('r100_4ArH.mat')\n",
    "r100_4ArH  = outdict['r100_4ArH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-score estimate (edges)\n",
    "zscore_AH=np.zeros((2,4,7,32,32)) \n",
    "for syn in range(2):\n",
    "    for st in range(4): # only for mutual\n",
    "        for freq in range(7):\n",
    "            for i in range(32):\n",
    "                for j in range(32):\n",
    "                    r_distri_random = r100_4ArH[:,syn,st,freq,i,j]\n",
    "                    r_AH_real=r_AH[syn,st,freq,i,j]\n",
    "                    r_distri_random = [r_AH_real]+r_distri_random.tolist()\n",
    "                    zscores=stats.zscore(r_distri_random)\n",
    "                    zscore_AH[syn,st,freq,i,j]=zscores[0]\n",
    "                    del(r_distri_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute degree centrality (nodes)\n",
    "cc3_syn=np.zeros((1,2,4,36,7,32))\n",
    "for syn in range(2):\n",
    "    for st in range(4):\n",
    "        for freq in range(7):\n",
    "            for tr in range(36):\n",
    "                G=nx.from_numpy_array(A_syn[syn][st][tr,freq,:,:])\n",
    "                x0=nx.clustering(G)\n",
    "                x1=nx.degree_centrality(G)\n",
    "                x2=nx.betweenness_centrality(G)\n",
    "                del(G)\n",
    "                for chan in range(32):\n",
    "                    cc3_syn[0,syn,st,tr,freq,chan]=x1[chan]\n",
    "# 10 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real correlation (nodes)\n",
    "r_ccH=np.zeros((1,2,4,7,32))\n",
    "p_ccH=np.zeros((1,2,4,7,32))\n",
    "for ccc in range(1):\n",
    "    for syn in range(2):\n",
    "        for st in range(4):\n",
    "            for freq in range(7):\n",
    "                for chan in range(32):\n",
    "                    r_ccH[ccc,syn,st,freq,chan],p_ccH[ccc,syn,st,freq,chan]= pearsonr(\n",
    "                        cc3_syn[ccc,syn,st,:,freq,chan],H_syn[syn][st])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # This step takes hours, output was saved already, can skip to save time\n",
    "# # simulate 36 random network to get a correlation then repeat 100 times (nodes)\n",
    "# r100_4crH=np.zeros((100,1,2,4,7,32)) # Distribution\n",
    "# for r in range(100):\n",
    "#     # construct 36 random network with matched number of edges\n",
    "#     cr3_syn=np.zeros((2,4,7,36,3,32)) # 36 random graph\n",
    "#     for syn in range(2):\n",
    "#         for st in range(4): # all condition\n",
    "#             for tr in range(36):\n",
    "#                 for freq in range(7):\n",
    "#                     G=nx.from_numpy_array(A_syn[syn][st][tr,freq,:,:])\n",
    "#                     nEdges = len(G.edges())\n",
    "#                     R=nx.gnm_random_graph(32, nEdges, seed=None, directed=False)\n",
    "#                     xr=np.zeros((3,32))\n",
    "#                     for chan in range(32):\n",
    "#                         xr[0,chan]=nx.clustering(R)[chan]\n",
    "#                         xr[1,chan]=nx.degree_centrality(R)[chan]\n",
    "#                         xr[2,chan]=nx.betweenness_centrality(R)[chan]\n",
    "#                     cr3_syn[syn,st,freq,tr,:,:]=xr\n",
    "#     # compute correlation\n",
    "#     r_crH=np.zeros((1,2,4,7,32))\n",
    "#     p_crH=np.zeros((1,2,4,7,32))\n",
    "#     for c in range(1):\n",
    "#         for syn in range(2):\n",
    "#             for st in range(4):\n",
    "#                 for freq in range(7):\n",
    "#                     for chan in range(32):\n",
    "#                         r_crH[c,syn,st,freq,chan],p_crH[c,syn,st,freq,chan]= pearsonr(\n",
    "#                             cr3_syn[syn,st,freq,:,c,chan],H_syn[syn][st])\n",
    "#                     r100_4crH[r,c,syn,st,freq,:]=r_crH[c,syn,st,freq,:]\n",
    "# # 2h x 4 st = 8 h\n",
    "# outdict = dict()\n",
    "# outdict['r100_4crH']       = r100_4crH\n",
    "# savemat('r100_4crH',outdict,store_python_metadata = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdict = dict()\n",
    "outdict['r100_4crH']       = r100_4crH\n",
    "savemat('r100_4crH',outdict,store_python_metadata = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdict=loadmat('r100_4crH.mat')\n",
    "r100_4crH  = outdict['r100_4crH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-score estimate (nodes)\n",
    "zscore_crH=np.zeros((1,2,4,7,32))\n",
    "for ccc in range(1):\n",
    "    for syn in range(2):\n",
    "        for st in range(4): # only for mutual\n",
    "            for freq in range(7):\n",
    "                for chan in range(32):\n",
    "                    crH_distri_random=r100_4crH[:,ccc,syn,st,freq,chan]\n",
    "                    r_crH_real=r_ccH[ccc,syn,st,freq,chan]\n",
    "                    r_distri_random=[r_crH_real]+crH_distri_random.tolist()\n",
    "                    zscores=stats.zscore(r_distri_random)\n",
    "                    zscore_crH[ccc,syn,st,freq,chan]=zscores[0]\n",
    "# 0.5 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot for publication\n",
    "# plot the zscore in networkx\n",
    "import copy\n",
    "ctr3names=['degree centrality']\n",
    "greek_labels=['θ','α','μ','β1','β2',]\n",
    "vmin_node_c=-3\n",
    "vmax_node_c=3\n",
    "vmin_edge_c=-3\n",
    "vmax_edge_c=3\n",
    "zscore_lim=2\n",
    "for ccc in range(1):\n",
    "        for st in range(3,4):\n",
    "            fig, ax = plt.subplots(5,2,figsize=(6*2, 6*5))\n",
    "            for syn in range(2):\n",
    "                    for freq in range(1,6):\n",
    "                            plt.sca(ax[freq-1, syn])\n",
    "                            data = zscore_AH[syn,st,freq,:,:]\n",
    "                            X=nx.from_numpy_array(data)\n",
    "                            X.remove_edges_from(nx.selfloop_edges(X))\n",
    "                            edges,edge_colors = zip(*nx.get_edge_attributes(X,'weight').items())\n",
    "                            copy_edge_colors=np.asarray(copy.deepcopy(edge_colors))\n",
    "                            for e in range(len(copy_edge_colors)):\n",
    "                                    if copy_edge_colors[e]<zscore_lim and copy_edge_colors[e]>-1*zscore_lim:\n",
    "                                            copy_edge_colors[e]=0\n",
    "\n",
    "                            ctr32=copy.deepcopy(zscore_crH[ccc,syn,st,freq,:])\n",
    "                            for chan in range(32):\n",
    "                                    if ctr32[chan]<zscore_lim and ctr32[chan]>-1*zscore_lim:\n",
    "                                            ctr32[chan]=0\n",
    "\n",
    "                                            \n",
    "                            nx.draw_networkx_labels(X, pos, labels=labeldict, font_size=15,font_weight=4)\n",
    "                            nodes=nx.draw_networkx_nodes(X, pos, node_size=300, \n",
    "                                            node_color=ctr32, vmin=vmin_node_c, vmax=vmax_node_c, \n",
    "                                            cmap='bwr', alpha=0.3)\n",
    "                            edges=nx.draw_networkx_edges(X, pos, width=2, \n",
    "                                    edge_color=copy_edge_colors,edge_vmin=vmin_edge_c,edge_vmax=vmax_edge_c,\n",
    "                                    edge_cmap=plt.cm.bwr,alpha=0.3)\n",
    "                            title = greek_labels[freq-1]\n",
    "                            ax[freq-1, syn].set_title(title, fontsize = 20, color=syn2colors[syn], fontweight=\"bold\") \n",
    "                            ax[freq-1, syn].axis('off')\n",
    "\n",
    "\n",
    "                            fig.subplots_adjust(right=0.85)\n",
    "                            cbar_ax2 = fig.add_axes([0.88, 0.3, 0.01, 0.4])\n",
    "                            cbar_edges=fig.colorbar(nodes,cbar_ax2)\n",
    "                            cbar_edges.ax.tick_params(labelsize=20)\n",
    "\n",
    "\n",
    "            plt.suptitle(states4names[st]+'\\nnodes: zscore of the correlation between ' + ctr3names[ccc] + ' and H\\n'\n",
    "                    + 'edges: zscore of the correlation between pcorr and H  ',\n",
    "            fontsize=20)\n",
    "\n",
    "            plt.figtext(0.21,0.92,syn2names[0], fontsize=20, color=syn2colors[0], fontname=\"Times New Roman\", fontweight=\"bold\")\n",
    "            plt.figtext(0.62,0.92,syn2names[1], fontsize=20, color=syn2colors[1], fontname=\"Times New Roman\", fontweight=\"bold\")\n",
    "\n",
    "\n",
    "\n",
    "# 7s\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
