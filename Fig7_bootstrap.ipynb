{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/home/zhibinz2/Documents/GitHub/Motor_cordination/1_over_f/data_analysis/hyperscanEEG_correlation/permutation20250515ramesh_code.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "from matplotlib import pyplot as plt\n",
    "from hdf5storage import loadmat,savemat\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myimshow(data, title=None, cmap='bwr', vmin=-2, vmax=2):\n",
    "    plt.figure(figsize=(8, 6), layout='tight')\n",
    "    plt.imshow(data, cmap=cmap, vmin =vmin, vmax=vmax)\n",
    "    plt.colorbar(location='bottom')\n",
    "    plt.yticks(np.arange(data.shape[0]),labels=[r'$\\delta$',r'$\\theta$',r'$\\alpha$',r'$\\mu$',r'$\\beta_1$',r'$\\beta_2$',r'$\\gamma$'])\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = random.default_rng(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdict=loadmat('/home/zhibinz2/Documents/GitHub/Motor_coordination_code/cc3_syn.mat')\n",
    "cc3_syn=outdict['cc3_syn'] # 3nx x 2 syn x 4 condi x36 tr x 7 freq x 32 chan\n",
    "# 3nx means 3 different networkx measurements; 2syn means 2 task types (synch and synco); 4 condi means 4 conditions; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#degree centrality -dc efficiency -ef betweenness centrality -bc\n",
    "#36 tr means 36 trials; 7 freq means 7 frequency bands; 32 chan means 32 channels\n",
    "tasks = ['synch','synco']\n",
    "feedback = ['ind','lead','follow','mutual']\n",
    "dc = np.zeros((2*4*36,7,32))\n",
    "ef = np.zeros((2*4*36,7,32))\n",
    "bc = np.zeros((2*4*36,7,32))\n",
    "t = np.array(np.zeros((2*4*36)),dtype = 'str')\n",
    "f = np.array(np.zeros((2*4*36)),dtype = 'str')\n",
    "\n",
    "for j in range(2): # 2 syn\n",
    "    dc2 = np.zeros((4*36,7,32))\n",
    "    ef2 = np.zeros((4*36,7,32))\n",
    "    bc2 = np.zeros((4*36,7,32)) \n",
    "    f2 = np.array(np.zeros(4*36),dtype='str')\n",
    "    for k in range(4):\n",
    "        dc2[k*36:(k+1)*36,:,:]= cc3_syn[0,j,k,:,:,:]\n",
    "        ef2[k*36:(k+1)*36,:,:]= cc3_syn[1,j,k,:,:,:]\n",
    "        bc2[k*36:(k+1)*36,:,:]= cc3_syn[2,j,k,:,:,:]\n",
    "        f2[k*36:(k+1)*36] = feedback[k] # label condition\n",
    "    dc[j*4*36:(j+1)*4*36,:,:] = dc2\n",
    "    ef[j*4*36:(j+1)*4*36,:,:] = ef2\n",
    "    bc[j*4*36:(j+1)*4*36,:,:] = bc2\n",
    "    f[j*4*36:(j+1)*4*36] = f2\n",
    "    t[j*4*36:(j+1)*4*36] = tasks[j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the 144 indicies of following and mutual combined \n",
    "follow_mutual=(f == feedback[2]) | (f == feedback[3])\n",
    "tr_ind=np.where(follow_mutual)\n",
    "follow_mutual_ind=tr_ind[0]\n",
    "follow_mutual_ind "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets consider instead the way we did it in the first draft of the paper where we creare a null distribution and z-score the data. \n",
    "nsims = 20000\n",
    "x = rng.choice(follow_mutual_ind,size = (36,nsims),replace = True) # shuffle all 36 trials among only the 144 trials 20000 times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# degree centrality\n",
    "datax = np.zeros((nsims,7,32)) # the distribution of 20000 times\n",
    "for j in range(nsims):\n",
    "    datax[j,:,:] = np.mean(dc[x[:,j],:,:],axis  = 0) # average over 36 randomized trials\n",
    "dxmean = np.mean(datax,axis=0) # average over 20000 sim\n",
    "dxstd = np.std(datax,axis=0)\n",
    "\n",
    "# zscore\n",
    "# dataz = np.zeros((144,7,32)) # zscore (not needed, got updated to 7x 32 in each condition)\n",
    "\n",
    "dcsynch = dict()\n",
    "#Degree centrality \n",
    "for k in range(2,4):\n",
    "    dataz= np.mean(dc[(t == 'synch') & ((f == feedback[k])),:,:],axis =0)\n",
    "    dataz = (dataz - dxmean)/dxstd\n",
    "    dcsynch[feedback[k]] = dataz\n",
    "\n",
    "dcsynco = dict()\n",
    "for k in range(2,4):\n",
    "    dataz= np.mean(dc[(t == 'synco') & ((f == feedback[k])),:,:],axis =0)\n",
    "    dataz = (dataz - dxmean)/dxstd\n",
    "    dcsynco[feedback[k]] = dataz\n",
    "\n",
    "dctask = dict()\n",
    "for j in range(2):\n",
    "    dataz= np.mean(dc[((t == tasks[j]) & follow_mutual )],axis =0)\n",
    "    dataz = (dataz - dxmean)/dxstd\n",
    "    dctask[tasks[j]] = dataz\n",
    "\n",
    "dcfeed = dict()\n",
    "for k in range(2,4):\n",
    "    dataz= np.mean(dc[(f == feedback[k])],axis =0)\n",
    "    dataz = (dataz - dxmean)/dxstd\n",
    "    dcfeed[feedback[k]] = dataz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath='/home/zhibinz2/Documents/GitHub/Motor_cordination/1_over_f/data_analysis/hyperscanEEG_correlation/zscore_20250515/'\n",
    "savemat(savepath+'dcsynch.mat',  dcsynch)\n",
    "savemat(savepath+'dcsynco.mat',  dcsynco)\n",
    "savemat(savepath+'dctask.mat',   dctask)\n",
    "savemat(savepath+'dcfeed.mat',   dcfeed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# betweenness centrality   \n",
    "datax = np.zeros((nsims,7,32))\n",
    "for j in range(nsims):\n",
    "    datax[j,:,:] = np.mean(bc[x[:,j],:,:],axis  = 0)\n",
    "dxmean = np.mean(datax,axis=0)\n",
    "dxstd = np.std(datax,axis=0)\n",
    "\n",
    "# dataz = np.zeros((288,7,32))\n",
    "\n",
    "bcsynch = dict()\n",
    "for k in range(2,4):\n",
    "    dataz= np.mean(bc[(t == 'synch') & ((f == feedback[k])),:,:],axis =0)\n",
    "    dataz = (dataz - dxmean)/dxstd\n",
    "    bcsynch[feedback[k]] = dataz\n",
    "\n",
    "bcsynco = dict()\n",
    "for k in range(2,4):\n",
    "    dataz= np.mean(bc[(t == 'synco') & ((f == feedback[k])),:,:],axis =0)\n",
    "    dataz = (dataz - dxmean)/dxstd\n",
    "    bcsynco[feedback[k]] = dataz\n",
    "\n",
    "bctask = dict()\n",
    "for j in range(2):\n",
    "    dataz= np.mean(bc[(t == tasks[j]) & follow_mutual],axis =0)\n",
    "    dataz = (dataz - dxmean)/dxstd\n",
    "    bctask[tasks[j]] = dataz\n",
    "\n",
    "bcfeed = dict()\n",
    "for k in range(2,4):\n",
    "    dataz= np.mean(bc[(f == feedback[k])],axis =0)\n",
    "    dataz = (dataz - dxmean)/dxstd\n",
    "    bcfeed[feedback[k]] = dataz\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath='/home/zhibinz2/Documents/GitHub/Motor_cordination/1_over_f/data_analysis/hyperscanEEG_correlation/zscore_20250515/'\n",
    "savemat(savepath+'bcsynch.mat',  bcsynch)\n",
    "savemat(savepath+'bcsynco.mat',  bcsynco)\n",
    "savemat(savepath+'bctask.mat',   bctask)\n",
    "savemat(savepath+'bcfeed.mat',   bcfeed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(2,4):\n",
    "    myimshow(dcsynch[feedback[k]], title  = 'DC synch ' + feedback[k])\n",
    "    print(np.where(np.abs(dcsynch[feedback[k]]) > 1.96))\n",
    "\n",
    "# savemat('dcsynch.mat', {'dcsynch': dcsynch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(2,4):\n",
    "    myimshow(dcsynco[feedback[k]],title = 'DC synco ' + feedback[k])\n",
    "    print(np.where(np.abs(dcsynco[feedback[k]]) > 1.96))\n",
    "\n",
    "# savemat('dcsynco.mat', {'dcsynco': dcsynco})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(2,4):\n",
    "    myimshow(bcsynch[feedback[k]], title  = 'BC synch ' + feedback[k])\n",
    "    print(np.where(np.abs(bcsynch[feedback[k]]) > 1.96))\n",
    "\n",
    "# savemat('bcsynch.mat', {'bcsynch': bcsynch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(2,4):\n",
    "    myimshow(bcsynco[feedback[k]], title  = 'BC synco ' + feedback[k])\n",
    "    print(np.where(np.abs(bcsynco[feedback[k]]) > 1.96))\n",
    "\n",
    "# savemat('bcsynco.mat', {'bcsynco': bcsynco})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
